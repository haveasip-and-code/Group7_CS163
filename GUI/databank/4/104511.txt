Deutschland
The German word for Germany. Germany was originally going to be named something closer to Deutschland other than how it is until some asshole had to fuck it all up.

