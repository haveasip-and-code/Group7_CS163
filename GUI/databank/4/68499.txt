californication
Californication means when Western civilization has an effect on another state (or country). This isn't only limited to California. They mean all WESTERN states. Besides, all the smart Californians know that this state isn't just a beach, or one city (Hollywood)

